{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries are Loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "print(\"Libraries are Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data into a DataFrame\n",
    "data = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in 'Title' and 'Abstract' columns with empty strings\n",
    "data['Title'] = data['Title'].fillna('')\n",
    "data['Abstract'] = data['Abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Title' and 'Abstract' columns\n",
    "titles = data['Title'].tolist()\n",
    "abstracts = data['Abstract'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Tokenizer and Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        # Ensure that the input is a list of strings\n",
    "        if isinstance(text, str):\n",
    "            inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "            outputs = model(**inputs)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "            mean_pooled = torch.mean(last_hidden_states, dim=1).squeeze().detach().numpy()\n",
    "            embeddings.append(mean_pooled)\n",
    "        else:\n",
    "            # If the input is not a string, append a placeholder embedding\n",
    "            embeddings.append([0.0] * 327)  # Change 768 to the actual size of BERT embeddings\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BERT embeddings for titles and abstracts\n",
    "title_embeddings = get_bert_embeddings(titles)\n",
    "abstract_embeddings = get_bert_embeddings(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as \n"
     ]
    }
   ],
   "source": [
    "# Save the BERT embeddings as pickle files\n",
    "with open('title_bert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(title_embeddings, f)\n",
    "\n",
    "with open('abstract_bert_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(abstract_embeddings, f)\n",
    "\n",
    "print(\"Data saved successfully as \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for titles and abstracts with embeddings\n",
    "title_data = pd.DataFrame({'Title': titles})\n",
    "title_data['Embeddings'] = pd.DataFrame(title_embeddings).values.tolist()\n",
    "\n",
    "abstract_data = pd.DataFrame({'Abstract': abstracts})\n",
    "abstract_data['Embeddings'] = pd.DataFrame(abstract_embeddings).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the embeddings with the original DataFrame\n",
    "titleData = pd.concat([title_data['Title'], pd.DataFrame(title_data['Embeddings'].tolist(), columns=[f'embedding_{i}' for i in range(768)])], axis=1)\n",
    "abstractData = pd.concat([abstract_data['Abstract'], pd.DataFrame(abstract_data['Embeddings'].tolist(), columns=[f'embedding_{i}' for i in range(768)])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to CSV files\n",
    "titleData.to_csv('title_data_with_embeddings.csv', index=False)\n",
    "abstractData.to_csv('abstract_data_with_embeddings.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
